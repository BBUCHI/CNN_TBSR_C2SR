{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6391213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libaries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d818bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chemin des dossiers avec les données\n",
    "path = \"/home/bbuchi/Bureau/CNN/data\"\n",
    "path_C2SR = path+\"/C2SR\"\n",
    "path_TBSR = path+\"/TBSR\"\n",
    "\n",
    "#Taille des images (40,30)\n",
    "width = 40\n",
    "height = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfb8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE-\n"
     ]
    }
   ],
   "source": [
    "#Pour la création d'une image\n",
    "def to_img(nom, label, data) :\n",
    "    w, h = width, height\n",
    "    print(h)\n",
    "    d = np.zeros((h, w), dtype=np.uint8)\n",
    "    for i in range(0,h-1):\n",
    "        d[i] = data[i]*int(255/3)\n",
    "    img = Image.fromarray(d)\n",
    "    imgG = Image.fromarray(np.rot90(d))\n",
    "    imgD = Image.fromarray(np.fliplr(np.rot90(d)))\n",
    "    imgI = Image.fromarray(np.flipud(d))\n",
    "    img.save(\"bdd/\"+label+\"/\"+nom[:-4]+'.bmp')\n",
    "    #imgG.save(\"bdd/\"+label+\"/\"+nom[:-4]+'_G.bmp')\n",
    "    #imgD.save(\"bdd/\"+label+\"/\"+nom[:-4]+'_D.bmp')\n",
    "    #imgI.save(\"bdd/\"+label+\"/\"+nom[:-4]+'I.bmp')\n",
    "    img.show()\n",
    "\n",
    "#Créer les images à partir des fichiers CSV  \n",
    "def convert_all_img():\n",
    "    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)    \n",
    "    for img in os.listdir(path_C2SR) :\n",
    "            temp = pd.read_csv(path_C2SR+\"/\"+img,header=None);\n",
    "            temp = np.array(temp)\n",
    "            to_img(img,\"C2SR\",temp)\n",
    "    for img in os.listdir(path_TBSR) :\n",
    "            temp = pd.read_csv(path_TBSR+\"/\"+img,header=None);\n",
    "            temp = np.array(temp)\n",
    "            to_img(img,\"TBSR\",temp)\n",
    "\n",
    "print(\"DONE-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acad68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    data = []\n",
    "    for img in os.listdir(path_C2SR) :\n",
    "        path = path_C2SR+\"/\"+img\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        data.append([np.array(img), np.array([1,0])])\n",
    "    for img in os.listdir(path_TBSR) :\n",
    "        path = path_TBSR+\"/\"+img\n",
    "        #print(img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        data.append([np.array(img), np.array([0,1])])\n",
    "    shuffle(data);\n",
    "    #data = np.array(data,dtype=object)\n",
    "    np.save(\"data.npy\",data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b9b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE-\n"
     ]
    }
   ],
   "source": [
    "data = create_data()\n",
    "taille = len(data)\n",
    "taille_10p = int(taille*0.1)#10% des données\n",
    "\n",
    "train_test = data[:-taille_10p]\n",
    "train = train_test[:-taille_10p]\n",
    "test = train_test[-taille_10p:]\n",
    "valid = data[-taille_10p:]\n",
    "\n",
    "w_ = train[0][0][0].size\n",
    "h_ = int(train[0][0].size/w_)\n",
    "\n",
    "train_X = np.array([i[0] for i in train]).reshape(-1,w_,h_,1)\n",
    "train_X=train_X/255\n",
    "train_y = np.array([i[1] for i in train])\n",
    "\n",
    "test_X = np.array([i[0] for i in test]).reshape(-1,w_,h_,1)\n",
    "test_X=test_X/255\n",
    "test_y = np.array([i[1] for i in test])\n",
    "\n",
    "valid_X = np.array([i[0] for i in test]).reshape(-1,w_,h_,1)\n",
    "valid_X=valid_X/255\n",
    "valid_y = np.array([i[1] for i in test])\n",
    "\n",
    "y_ = []\n",
    "for i in train_y:\n",
    "    if i[0] == 1 :\n",
    "        y_.append(0)\n",
    "    else :\n",
    "        y_.append(1)\n",
    "y_ = np.array(y_)\n",
    "train_y = y_\n",
    "\n",
    "y_ = []\n",
    "for i in test_y:\n",
    "    if i[0] == 1 :\n",
    "        y_.append(0)\n",
    "    else :\n",
    "        y_.append(1)\n",
    "y_ = np.array(y_)\n",
    "test_y = y_\n",
    "\n",
    "y_ = []\n",
    "for i in valid_y:\n",
    "    if i[0] == 1 :\n",
    "        y_.append(0)\n",
    "    else :\n",
    "        y_.append(1)\n",
    "y_ = np.array(y_)\n",
    "valid_y = y_\n",
    "\n",
    "\n",
    "print(\"DONE-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d2c8eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 38, 28, 10)        100       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 19, 14, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 12, 16)        1456      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 8, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               92280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 170       \n",
      "=================================================================\n",
      "Total params: 104,170\n",
      "Trainable params: 104,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 36, 26, 10)        260       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 18, 13, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 9, 16)         4016      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 7, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               53880     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 170       \n",
      "=================================================================\n",
      "Total params: 68,490\n",
      "Trainable params: 68,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#Le CNN\n",
    "k1=3\n",
    "k2=5\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=10, kernel_size=(k1,k1), activation=\"relu\", input_shape=(width,height,1)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(k1,k1), activation=\"relu\"))\n",
    "model.add(layers.AveragePooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120, activation=\"relu\"))\n",
    "model.add(layers.Dense(84, activation=\"relu\"))\n",
    "model.add(layers.Dense(2, activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "modelBig = models.Sequential()\n",
    "modelBig.add(layers.Conv2D(filters=10, kernel_size=(k2,k2), activation=\"relu\", input_shape=(width,height,1)))\n",
    "modelBig.add(layers.AveragePooling2D())\n",
    "modelBig.add(layers.Conv2D(filters=16, kernel_size=(k2,k2), activation=\"relu\"))\n",
    "modelBig.add(layers.AveragePooling2D())\n",
    "modelBig.add(layers.Flatten())\n",
    "modelBig.add(layers.Dense(120, activation=\"relu\"))\n",
    "modelBig.add(layers.Dense(84, activation=\"relu\"))\n",
    "modelBig.add(layers.Dense(2, activation=\"softmax\"))\n",
    "modelBig.summary()\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f54eca85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.6894 - accuracy: 0.5248 - val_loss: 0.6833 - val_accuracy: 0.5333\n",
      "Epoch 2/80\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 0.6735 - accuracy: 0.5744 - val_loss: 0.6657 - val_accuracy: 0.5333\n",
      "Epoch 3/80\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.6595 - accuracy: 0.5744 - val_loss: 0.6545 - val_accuracy: 0.5333\n",
      "Epoch 4/80\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.6539 - accuracy: 0.5744 - val_loss: 0.6419 - val_accuracy: 0.5333\n",
      "Epoch 5/80\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 0.6459 - accuracy: 0.6033 - val_loss: 0.6293 - val_accuracy: 0.6667\n",
      "Epoch 6/80\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.6485 - accuracy: 0.6198 - val_loss: 0.6210 - val_accuracy: 0.6667\n",
      "Epoch 7/80\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6422 - accuracy: 0.6198 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
      "Epoch 8/80\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.6345 - accuracy: 0.6198 - val_loss: 0.6012 - val_accuracy: 0.7000\n",
      "Epoch 9/80\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 0.6331 - accuracy: 0.6570 - val_loss: 0.5866 - val_accuracy: 0.6667\n",
      "Epoch 10/80\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6354 - accuracy: 0.6281 - val_loss: 0.6162 - val_accuracy: 0.6667\n",
      "Epoch 11/80\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6263 - accuracy: 0.6405 - val_loss: 0.5699 - val_accuracy: 0.8667\n",
      "Epoch 12/80\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6140 - accuracy: 0.6653 - val_loss: 0.5581 - val_accuracy: 0.7667\n",
      "Epoch 13/80\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5981 - accuracy: 0.6942 - val_loss: 0.5252 - val_accuracy: 0.8667\n",
      "Epoch 14/80\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5960 - accuracy: 0.6942 - val_loss: 0.5179 - val_accuracy: 0.8667\n",
      "Epoch 15/80\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5752 - accuracy: 0.7851 - val_loss: 0.4902 - val_accuracy: 0.9000\n",
      "Epoch 16/80\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 0.5568 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.8333\n",
      "Epoch 17/80\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.5521 - accuracy: 0.7893 - val_loss: 0.4730 - val_accuracy: 0.9000\n",
      "Epoch 18/80\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.5339 - accuracy: 0.8182 - val_loss: 0.4888 - val_accuracy: 0.8000\n",
      "Epoch 19/80\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.5347 - accuracy: 0.8058 - val_loss: 0.4982 - val_accuracy: 0.8333\n",
      "Epoch 20/80\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.5199 - accuracy: 0.8017 - val_loss: 0.4523 - val_accuracy: 0.9333\n",
      "Epoch 21/80\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4901 - accuracy: 0.8430 - val_loss: 0.5107 - val_accuracy: 0.7667\n",
      "Epoch 22/80\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.4922 - accuracy: 0.8306 - val_loss: 0.4324 - val_accuracy: 0.9000\n",
      "Epoch 23/80\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 0.4626 - accuracy: 0.8719 - val_loss: 0.4256 - val_accuracy: 0.9333\n",
      "Epoch 24/80\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4671 - accuracy: 0.8471 - val_loss: 0.4261 - val_accuracy: 0.9000\n",
      "Epoch 25/80\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.4484 - accuracy: 0.8760 - val_loss: 0.4143 - val_accuracy: 0.9333\n",
      "Epoch 26/80\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.4376 - accuracy: 0.8926 - val_loss: 0.4076 - val_accuracy: 0.9333\n",
      "Epoch 27/80\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.4375 - accuracy: 0.8760 - val_loss: 0.4110 - val_accuracy: 0.9000\n",
      "Epoch 28/80\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.4274 - accuracy: 0.8926 - val_loss: 0.4446 - val_accuracy: 0.9000\n",
      "Epoch 29/80\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.4491 - accuracy: 0.8636 - val_loss: 0.4363 - val_accuracy: 0.9000\n",
      "Epoch 30/80\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.4383 - accuracy: 0.8802 - val_loss: 0.4012 - val_accuracy: 0.9333\n",
      "Epoch 31/80\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 0.4195 - accuracy: 0.8926 - val_loss: 0.3969 - val_accuracy: 0.9333\n",
      "Epoch 32/80\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.4160 - accuracy: 0.9174 - val_loss: 0.3907 - val_accuracy: 0.9333\n",
      "Epoch 33/80\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.4071 - accuracy: 0.9132 - val_loss: 0.3907 - val_accuracy: 0.9333\n",
      "Epoch 34/80\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.4065 - accuracy: 0.9091 - val_loss: 0.3874 - val_accuracy: 0.9333\n",
      "Epoch 35/80\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.4004 - accuracy: 0.9132 - val_loss: 0.3920 - val_accuracy: 0.9333\n",
      "Epoch 36/80\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.3987 - accuracy: 0.9132 - val_loss: 0.3851 - val_accuracy: 0.9333\n",
      "Epoch 37/80\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 0.3969 - accuracy: 0.9215 - val_loss: 0.3858 - val_accuracy: 0.9333\n",
      "Epoch 38/80\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 0.3952 - accuracy: 0.9256 - val_loss: 0.3860 - val_accuracy: 0.9333\n",
      "Epoch 39/80\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3915 - accuracy: 0.9339 - val_loss: 0.3809 - val_accuracy: 0.9333\n",
      "Epoch 40/80\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.3884 - accuracy: 0.9339 - val_loss: 0.3819 - val_accuracy: 0.9333\n",
      "Epoch 41/80\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 0.3857 - accuracy: 0.9339 - val_loss: 0.3802 - val_accuracy: 0.9333\n",
      "Epoch 42/80\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.3822 - accuracy: 0.9380 - val_loss: 0.3762 - val_accuracy: 0.9333\n",
      "Epoch 43/80\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.3806 - accuracy: 0.9380 - val_loss: 0.3833 - val_accuracy: 0.9333\n",
      "Epoch 44/80\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3748 - accuracy: 0.9463 - val_loss: 0.3717 - val_accuracy: 0.9333\n",
      "Epoch 45/80\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3698 - accuracy: 0.9545 - val_loss: 0.3818 - val_accuracy: 0.9333\n",
      "Epoch 46/80\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3669 - accuracy: 0.9545 - val_loss: 0.3695 - val_accuracy: 0.9333\n",
      "Epoch 47/80\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3629 - accuracy: 0.9628 - val_loss: 0.3657 - val_accuracy: 0.9667\n",
      "Epoch 48/80\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3627 - accuracy: 0.9545 - val_loss: 0.3677 - val_accuracy: 0.9667\n",
      "Epoch 49/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.3615 - accuracy: 0.9628 - val_loss: 0.3884 - val_accuracy: 0.9000\n",
      "Epoch 50/80\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.3711 - accuracy: 0.9504 - val_loss: 0.3652 - val_accuracy: 0.9667\n",
      "Epoch 51/80\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.3553 - accuracy: 0.9628 - val_loss: 0.3587 - val_accuracy: 0.9667\n",
      "Epoch 52/80\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 0.3544 - accuracy: 0.9711 - val_loss: 0.3571 - val_accuracy: 0.9667\n",
      "Epoch 53/80\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.3501 - accuracy: 0.9752 - val_loss: 0.3583 - val_accuracy: 0.9667\n",
      "Epoch 54/80\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.3512 - accuracy: 0.9711 - val_loss: 0.3546 - val_accuracy: 0.9667\n",
      "Epoch 55/80\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.3502 - accuracy: 0.9752 - val_loss: 0.3543 - val_accuracy: 0.9667\n",
      "Epoch 56/80\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.3480 - accuracy: 0.9752 - val_loss: 0.3497 - val_accuracy: 0.9667\n",
      "Epoch 57/80\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.3572 - accuracy: 0.9669 - val_loss: 0.3572 - val_accuracy: 0.9667\n",
      "Epoch 58/80\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.3453 - accuracy: 0.9793 - val_loss: 0.3524 - val_accuracy: 0.9667\n",
      "Epoch 59/80\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.3468 - accuracy: 0.9752 - val_loss: 0.3601 - val_accuracy: 0.9667\n",
      "Epoch 60/80\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.3571 - accuracy: 0.9711 - val_loss: 0.3280 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 0.3486 - accuracy: 0.9711 - val_loss: 0.3528 - val_accuracy: 0.9667\n",
      "Epoch 62/80\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.3478 - accuracy: 0.9711 - val_loss: 0.3529 - val_accuracy: 0.9667\n",
      "Epoch 63/80\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3465 - accuracy: 0.9752 - val_loss: 0.3519 - val_accuracy: 0.9667\n",
      "Epoch 64/80\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.3490 - accuracy: 0.9711 - val_loss: 0.3483 - val_accuracy: 0.9667\n",
      "Epoch 65/80\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.3436 - accuracy: 0.9752 - val_loss: 0.3489 - val_accuracy: 0.9667\n",
      "Epoch 66/80\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.3451 - accuracy: 0.9752 - val_loss: 0.3543 - val_accuracy: 0.9667\n",
      "Epoch 67/80\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.3437 - accuracy: 0.9793 - val_loss: 0.3511 - val_accuracy: 0.9667\n",
      "Epoch 68/80\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.3407 - accuracy: 0.9752 - val_loss: 0.3499 - val_accuracy: 0.9667\n",
      "Epoch 69/80\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.3395 - accuracy: 0.9793 - val_loss: 0.3497 - val_accuracy: 0.9667\n",
      "Epoch 70/80\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.3388 - accuracy: 0.9793 - val_loss: 0.3498 - val_accuracy: 0.9667\n",
      "Epoch 71/80\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 0.3381 - accuracy: 0.9793 - val_loss: 0.3492 - val_accuracy: 0.9667\n",
      "Epoch 72/80\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.3378 - accuracy: 0.9793 - val_loss: 0.3491 - val_accuracy: 0.9667\n",
      "Epoch 73/80\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3378 - accuracy: 0.9793 - val_loss: 0.3491 - val_accuracy: 0.9667\n",
      "Epoch 74/80\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.3373 - accuracy: 0.9793 - val_loss: 0.3487 - val_accuracy: 0.9667\n",
      "Epoch 75/80\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3374 - accuracy: 0.9793 - val_loss: 0.3488 - val_accuracy: 0.9667\n",
      "Epoch 76/80\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3369 - accuracy: 0.9793 - val_loss: 0.3486 - val_accuracy: 0.9667\n",
      "Epoch 77/80\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3367 - accuracy: 0.9793 - val_loss: 0.3483 - val_accuracy: 0.9667\n",
      "Epoch 78/80\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3366 - accuracy: 0.9793 - val_loss: 0.3485 - val_accuracy: 0.9667\n",
      "Epoch 79/80\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 0.3364 - accuracy: 0.9793 - val_loss: 0.3483 - val_accuracy: 0.9667\n",
      "Epoch 80/80\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.3363 - accuracy: 0.9793 - val_loss: 0.3481 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "#Entrainer le réseau de neurones\n",
    "from tensorflow import keras\n",
    "opt=keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_X, train_y, epochs=80, validation_data=(test_X,test_y))\n",
    "\n",
    "#modelBig.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              #metrics=['accuracy'])\n",
    "#historyBig = modelBig.fit(train_X, train_y, epochs=25, validation_data=(test_X,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "330c62da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.9667\n",
      "\n",
      "accuracy: 96.67%\n",
      "=================================\n",
      "1 +7\n",
      "0 (13)   &&   1 (17)\n"
     ]
    }
   ],
   "source": [
    "#Affiche les résultats pour les données qui n'ont pas servi à l'entrainement du systeme\n",
    "#shfl()\n",
    "#predictions = model.predict_classes(valid_X)\n",
    "#print(valid_y)\n",
    "scores = model.evaluate(valid_X,valid_y)\n",
    "#scoresBig = modelBig.evaluate(valid_X,valid_y)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (modelBig.metrics_names[1], scoresBig[1]*100))\n",
    "print(\"=================================\")\n",
    "\n",
    "predictions = model.predict_classes(valid_X)\n",
    "#predictionsBig = modelBig.predict_classes(valid_X)\n",
    "\n",
    "\n",
    "ind = 1\n",
    "ok1=0\n",
    "ok0=0\n",
    "takes = ok1;\n",
    "for i, j in zip(predictions , valid_y):\n",
    "    #print( \"{} <= {} // {} + {}:{}\".format(j,i,i==j,ok0,ok1))\n",
    "    if j==1:\n",
    "        ok1=ok1+1\n",
    "        takes = \"1 +\"+str(ok1)\n",
    "    else:\n",
    "        ok0=ok0+1\n",
    "        takes = \"0 +\"+str(ok0)\n",
    "    if i!=j :\n",
    "        print(str(takes))\n",
    "    ind = ind+1\n",
    "print(\"0 (\"+str(ok0)+\")   &&   1 (\"+str(ok1)+\")\")\n",
    "\n",
    "#print(\"-------------\")\n",
    "\n",
    "ind = 92\n",
    "#for i, j in zip(predictionsBig , valid_y):\n",
    "#    print( \"{}| {} <= {} // {}\".format(ind,j,i,i==j))\n",
    "#    ind = ind+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
